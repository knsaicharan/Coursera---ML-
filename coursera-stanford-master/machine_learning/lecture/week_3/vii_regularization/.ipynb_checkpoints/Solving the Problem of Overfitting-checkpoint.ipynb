{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1) The Problem of Overfitting](#1%29-The-Problem-of-Overfitting)\n",
    "    * [1) Understanding Overfitting](#1%29-Understanding-Overfitting)\n",
    "\t* [2) Addressing Overfitting](#2%29-Addressing-Overfitting)\n",
    "* [2) Cost function](#2%29-Cost-function)\n",
    "* [3) Regularized Linear Regression](#3%29-Regularized-Linear-Regression)\n",
    "\t* [1) Gradient Descent](#1%29-Gradient-Descent)\n",
    "\t* [2) Normal equation](#2%29-Normal-equation)\n",
    "* [4) Regularized Logistic Regression](#4%29-Regularized-Logistic-Regression)\n",
    "    * [1) Regularization term](#1%29-Regularization-term)\n",
    "\t* [2) Gradient Descent](#2%29-Gradient-Descent)\n",
    "    * [3) Advanced optimization](#3%29-Advanced-optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) The Problem of Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Understanding Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What I'd like to do is explain to you what is this **overfitting problem**, and we'll talk about a technique called **regularization**, that will allow us to **ameliorate or to reduce** this overfitting problem and get these learning algorithms to maybe work much better. So what is overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider the example below**\n",
    "\n",
    "For the **first example**, we use a straight line to fit the data. But this isn't a very good model. Looking at the data, it seems pretty clear that as the size of the housing increases, the housing prices plateau, or kind of flattens out as we move to the right and so this algorithm does not fit the training and we call this problem **underfitting**, and another term for this is that this algorithm has **high bias**.\n",
    "- The term **\"high bias\"** is kind of a historical or technical one, but the idea is that if a fitting a straight line to the data, then, it's as if the algorithm has a **very strong preconception**, or a **very strong bias** that housing prices are going to vary linearly with their size and despite the data to the contrary. Despite the evidence of the contrary is preconceptions still are bias, still closes it to fit a straight line and this ends up being a poor fit to the data. \n",
    "\n",
    "For the **second example**, we could fit a quadratic functions, and that works pretty well.\n",
    "\n",
    "For the **third example**, we fit a fourth degree polynomial function to the data and we can actually fill a curve that process through all five of our training examples. But this is not a good model, this problem we call **overfitting**, and, another term for this is that this algorithm has **high variance**.\n",
    "- The term **high variance** is another historical or technical one. But, the intuition is that, if we're fitting such a high order polynomial, then, the hypothesis can fit almost any function and this face of possible hypothesis is just too large, it's too variable. And we don't have enough data to constrain it to give us a good hypothesis so that's called **overfitting**.\n",
    "\n",
    "**The problem of overfitting** comes when if we have too many features, then to learn hypothesis may fit the training set very well. So, your cost function may actually be very close to zero or may be even zero exactly, but you may then end up with a weird curve. It means you tries too hard to fit the training set, so that it even fails to generalize to new examples and fails to predict prices on new examples as well, and here the term generalized refers to how well a hypothesis applies even to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic01.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/ACpTQ/the-problem-of-overfitting) 2:16*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A similar example on logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic02.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/ACpTQ/the-problem-of-overfitting) 5:37*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic03.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/ACpTQ/the-problem-of-overfitting) 6:03*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Addressing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we think overfitting is occurring, what can we do to address it?\n",
    "\n",
    "- In the previous examples, we had one or two dimensional data so, we could just plot the hypothesis and see what was going on and select the appropriate degree polynomial. So plotting the hypothesis, could be one way to try to decide what degree polynomial to use.\n",
    "- But that doesn't always work. When we have so many features, it also becomes much harder to plot the data and it becomes much harder to visualize it, to decide what features to keep or not.\n",
    "\n",
    "If we have a lot of features, and, very little training data, then, over fitting can become a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic04.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/ACpTQ/the-problem-of-overfitting) 7:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic05.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/ACpTQ/the-problem-of-overfitting) 9:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about the main intuitions behind **how regularization works**.\n",
    "\n",
    "Consider the 2 following examples, if we were to fit a quadratic function to this data, it gives us a pretty good fit to the data. Whereas, if we were to fit an overly high order degree polynomial, we end up with a curve that may fit the training set very well, but overfit the data poorly, and, not generalize well.\n",
    "\n",
    "**Suppose we were to penalize, and, make the parameters theta 3 and theta 4 really small**.\n",
    "\n",
    "Here's what I mean, here is our optimization objective, or here is our optimization problem, where we minimize our usual squared error cause function. \n",
    "\n",
    "$$min \\dfrac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{i}) - y^{i})^{2}$$\n",
    "\n",
    "Let's say I take this objective and modify it and add to it, plus 1000 theta 3 squared, plus 1000 theta 4 squared\n",
    "\n",
    "$$\\sum_{i=1}^m(h_{\\theta}(x^{i}) - y^{i})^{2} + 1000(\\theta_{3}^{2}) + 1000(\\theta_{4}^{2})$$\n",
    "\n",
    "Now, if we were to minimize this function, the only way to make this new cost function small is if theta 3 and data 4 are small. Because otherwise, if you have a thousand times theta 3, this new cost functions gonna be big.\n",
    "\n",
    "So when we minimize this new function we are going to end up with theta 3 close to 0 and theta 4 close to 0, and it is like we are getting rid of these two terms theta 3 and theta 4 in the function. And if we do that, then we are being left with a quadratic function, and we end up with a fit to the data, that's a quadratic function plus maybe, tiny contributions from small terms, theta 3, theta 4, that they may be very close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic06.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/B1MnL/cost-function) 2:17*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the idea behind regularization**\n",
    "\n",
    "- If we have small values for the parameters, then it usually correspond to having a simpler hypothesis. So, for our last example, we penalize just theta 3 and theta 4 and when both of these were close to zero, we wound up with a much simpler hypothesis that was essentially a quadratic function. But more generally, it is possible to show that **having smaller values of the parameters corresponds to usually smoother functions as well for the simpler.** And which are therefore, also, less prone to overfitting.\n",
    "\n",
    "**Let's look at the specific example:**\n",
    "\n",
    "For a housing prediction problem, we have:\n",
    "- hundred of features: $x_{1}, x_{2}, ..., x_{100}$\n",
    "- hundred of parameter: $\\theta_{1}, \\theta_{2}, ..., \\theta_{100}$\n",
    "And unlike the polynomial example, we don't know that theta 3, theta 4, are the high order polynomial terms. So, if we have just a bag, or a set of a hundred features, it's hard to pick in advance which are the ones that are less likely to be relevant. In a hundred and one parameters, we don't know which ones to pick, to try to shrink. \n",
    "\n",
    "So, in regularization, what we're going to do, is take our cost function.\n",
    "$$J(\\theta) = \\dfrac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2}$$\n",
    "And what I'm going to do is, modify this cost function to shrink all of my parameters, because I don't know which one or two to try to shrink. So I am going to modify my cost function to add a term at the end.\n",
    "$$J(\\theta) = \\dfrac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2} + \\lambda\\sum_{i=1}^n\\theta_{j}^2 $$\n",
    "\n",
    "When I add an extra regularization term at the end, it means I will shrink all of my parameters theta 1, theta 2, theta 3 up to theta 100. And by convention the summation here starts from one so I am not actually going penalize theta zero being large. Because the sum starts from i = 1 through n. But in practice, it makes very little difference, whether you include theta zero or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic07.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/B1MnL/cost-function) 5:55*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing down our regularized optimization objective, our regularized cost function again.\n",
    "$$J(\\theta) = \\dfrac{1}{2m}\\Big[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2} + \\lambda\\sum_{i=1}^n\\theta_{j}^2 \\Big]$$\n",
    "\n",
    "We have: \n",
    "- regularization term: $\\lambda\\sum_{i=1}^n\\theta_{j}^2$\n",
    "- regularization parameter (lambda): $\\lambda$\n",
    "\n",
    "What lambda does, is it controls a trade off between two different goals.\n",
    "- The first goal, capture it by the first goal objective, is that we would like to fit the training data well.\n",
    "- The second goal is, we want to keep the parameters small, and that's captured by the second term, by the regularization objective.\n",
    "\n",
    "What lambda, the regularization parameter does is the controls the trade of between these two goals, between the goal of fitting the training set well and the goal of keeping the parameter plan small and therefore keeping the hypothesis relatively simple to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic08.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/B1MnL/cost-function) 7:30*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic09.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/B1MnL/cost-function) 7:59*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regularized linear regression, if the regularization parameter monitor is set to be very large, then what will happen is we will end up penalizing the parameters theta 1, theta 2, theta 3, theta 4 very highly. We may end up with all of these parameters close to zero. And if we do that, then we're just left with a hypothesis:\n",
    "$$\\large h_\\theta(x) = \\theta_{0}$$\n",
    "\n",
    "That's mean we just fit a flat horizontal straight line to the data. And **this is an example of underfitting.** And another way of saying this is that this hypothesis has too strong a preconception or too high bias that housing prices are just equal to theta zero, and despite the clear data to the contrary, you choose to fit a flat horizontal line. \n",
    "\n",
    "So for regularization to work well, some care should be taken, to choose a good choice for the regularization parameter lambda as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic10.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/B1MnL/cost-function) 9:36*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For linear regression, we have previously worked out two learning algorithms: gradient descent and normal equation. We'll take those two algorithms and generalize them to the case of regularized linear regression.\n",
    "\n",
    "Here's the optimization objective that we came up with last time for regularized linear regression.\n",
    "$$J(\\theta) = \\dfrac{1}{2m}\\bigg[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2} + \\lambda\\sum_{i=1}^n\\theta_{j}^2 \\bigg]$$\n",
    "$$\\underset{\\theta}min J(\\theta)$$\n",
    "\n",
    "This first part is our usual objective for linear regression: $\\dfrac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2}$\n",
    "\n",
    "And we now have this additional regularization term: $\\lambda \\sum_{i=1}^n \\theta_{j}^2$, where lambda is our regularization parameter, and we like to find parameters theta that minimizes this cost function, this regularized cost function, $J(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic11.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) 00:31*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we were using gradient descent for the original cost function without the regularization term. And we had the following algorithm, for regular linear regression, without regularization, we would repeatedly update the parameters theta J as follows for J equals 0, 1, 2, up through n.\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$\n",
    "$$(j = 0,1,2,3,...,n)$$\n",
    "\n",
    "I'm going to write the update for theta 0 separately than for the update for the parameters 1, 2, 3, and so on up to n. And the reason I want to do this is you may remember that for our regularized linear regression, we penalize the parameters theta 1, theta 2, and so on up to theta n. But we don't penalize theta 0. So, when we modify this algorithm for regularized linear regression, we're going to end up treating theta zero slightly differently.\n",
    "\n",
    "$$\\theta_{0} := \\theta_{0} - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)}$$\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$\n",
    "$$(j = 1,2,3,...,n)$$\n",
    "\n",
    "Concretely, if we want to take this algorithm and modify it to use the regular rise objective, all we need to do is take this term at the bottom and modify it as follows:\n",
    "$$\\theta_{0} := \\theta_{0} - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)}$$\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha \\dfrac{1}{m}\\Big[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{j}\\Big]$$\n",
    "$$(j = 1,2,3,...,n)$$\n",
    "\n",
    "Using calculus with the function above, we know that this term in square brackets is the partial derivative with respect to $J({\\theta})$ using the new definition of $J({\\theta})$ with the regularization term\n",
    "\n",
    "$$ \\dfrac{\\partial}{\\partial\\theta_{j}}J(\\theta) = \\Big[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{j}\\Big]$$\n",
    "\n",
    "And similarly, this term up on top is the partial derivative respect of theta zero of $J({\\theta})$\n",
    "$$ \\dfrac{\\partial}{\\partial\\theta_{j}}J(\\theta) = \\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{i}$$\n",
    "\n",
    "Also, if you group all the terms together that depend on theta j, you can show that this update can be written equivalently as follows:\n",
    "\n",
    "$$\\theta_{j} := \\theta_{j}(1 - \\alpha\\dfrac{\\lambda}{m}) - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic12.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) 03:42*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term $(1 - \\alpha\\dfrac{\\lambda}{m})$ is a pretty interesting term., and it has an interesting effect. This term here is going to be a number that is usually a little bit less than one, because alpha times lambda over m is going to be positive, and usually if your learning rate is small and if m is large, this is usually pretty small. So this term here is gonna be a number\n",
    "that's usually a little bit less than 1, so think of it as a number like 0.99.\n",
    "\n",
    "The effect of our update to $\\theta{j}$ is we're going to say that $\\theta{j}$ gets replaced by ($\\theta{j}$ * 0.99), so we are \n",
    "shrinking theta j a little bit towards zero, and it makes theta j a bit smaller.\n",
    "\n",
    "The second term here: $\\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$, that's actually exactly the same as the original gradient descent update that we had, before we added all this regularization stuff.\n",
    "\n",
    "When we're using a regularized linear regression, what we're doing is on every iteration we're multiplying theta j by a number that's a little bit less then one, so its shrinking the parameter a little bit, and then we're performing a similar update as before. Of course that's just the intuition behind what this particular update is doing. Mathematically what it's doing\n",
    "is it's exactly gradient descent on the cost function J of theta that we defined on the previous slide that uses the regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic13.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) 05:15*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent was just one of our two algorithms for fitting a linear regression model. The second algorithm was the one\n",
    "based on the **normal equation**, where what we did was we created the design matrix X where each row corresponded to a separate training example. And we created a vector y, that's an m dimensional vector, and that contained the labels from my training set. So whereas X is an m by (n+1) dimensional matrix, y is an m dimensional vector. And in order to minimize the cost function J, we have:\n",
    "$$\\underset{\\theta}min J(\\theta)$$\n",
    "$$\\large \\theta = (X^{T}X)^{-1}X^{T}y$$\n",
    "\n",
    "This function above minimizes the cost function $J({\\theta})$, when we were not using regularization. \n",
    "\n",
    "Now that we are using regularization, if you were to derive what the minimum is, and just to give you a sense of how to\n",
    "derive the minimum. The way you derive it is you take partial derivatives with respect to each parameter. Set this to zero, and\n",
    "then do a bunch of math and you can then show that it's a formula like this that minimizes the cost function. \n",
    "\n",
    "$$\\dfrac{\\partial}{\\partial\\theta_{j}}J({\\theta}) = 0$$\n",
    "\n",
    "And concretely, if you are using regularization, then this formula changes as follows. Inside this parenthesis, you end up with a matrix like this. The upper left-most entry is 0, there are ones on the diagonals, and then zeros everywhere else in this matrix.\n",
    "\n",
    "More generally, this matrix is an (n+1) by (n+1) dimensional matrix. For example, if n = 2, then this matrix is going to be a three by three matrix.\n",
    "\n",
    "$$\\begin{bmatrix} \n",
    "0 & 0 & 0 \n",
    "\\\\ 0 & 1 & 0 \n",
    "\\\\ 0 & 0 & 1 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic14.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) 08:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally I want to just quickly describe **the issue of non-invertibility**.\n",
    "\n",
    "Now, consider a setting where m, the number of examples, is less than or equal to n, the number of features. If you have fewer examples than features, than this matrix, $X^{T}X$ will be non-invertible, or singular, or the other term for this is the matrix will be degenerate. \n",
    "\n",
    "If you implement this in Octave anyway and you use the pinv function to take the pseudo inverse, it will kind of do the right thing, but it's not clear that it would give you a very good hypothesis, even though numerically the Octave pinv function will\n",
    "give you a result that kinda makes sense.\n",
    "\n",
    "Fortunately, regularization also takes care of this for us. And concretely, so long as the regularization parameter lambda is strictly greater than 0, it is actually possible to prove that this matrix, X transpose X plus lambda times this funny\n",
    "matrix here, it is possible to prove that this matrix will not be singular and that this matrix will be invertible. So using regularization also takes care of any non-invertibility issues of the X transpose X matrix as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic15.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) 10:10*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Regularization term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For logistic regression, we previously talked about two types of optimization algorithms. We talked about how to use gradient descent to optimize as cost function J of theta. And we also talked about advanced optimization methods. We'll show how you can adapt both of those techniquesin order to have them work for **regularized logistic regression**.\n",
    "\n",
    "We saw earlier that **Logistic Regression** can also be prone to overfitting if you fit it with a very high order polynomial features, where g is the sigmoid function and in particular you end up with a hypothesis, whose decision boundary to be just sort of an overly complex and extremely contortive function. Not necessarily polynomial ones, but just with a lot of features you can end up with overfitting. \n",
    "\n",
    "This was our cost function for logistic regression:\n",
    "$$J(\\theta) = -\\big[\\dfrac{1}{m}\\sum_{i=1}^m y^{(i)}\\log (h_{\\theta}(x^{(i)}) + (1 - y^{(i)})\\log (1 - h_{\\theta}(x^{(i)})\\big]$$\n",
    "\n",
    "And if we want to modify it to use regularization, all we need to do is add to it the following term:\n",
    "\n",
    "$$J(\\theta) = -\\big[\\dfrac{1}{m}\\sum_{i=1}^m y^{(i)}\\log (h_{\\theta}(x^{(i)}) + (1 - y^{(i)})\\log (1 - h_{\\theta}(x^{(i)})\\big]+ \\lambda\\sum_{i=1}^n\\theta_{j}^2$$\n",
    "\n",
    "And this has to effect of penalizing the parameters theta 1 theta 2 and so on up to theta N from being too large. So, when using regularization even when you have a lot of features, the regularization can help take care of the overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic16.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression) 2:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we actually implement this? The new function of Gradient Descent for logistic regression is similar to what we do for linear regression. We will add the extra regularization term: $\\dfrac{\\lambda}{m}\\theta_{j}$.\n",
    "\n",
    "$$\\theta_{0} := \\theta_{0} - \\alpha \\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)}$$\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha \\dfrac{1}{m}\\Big[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{j}\\Big]$$\n",
    "$$(j = 1,2,3,...,n)$$\n",
    "\n",
    "So this is not the same algorithm as regularized linear regression. Because the hypothesis is different.\n",
    "$$h_{\\theta}(x) = \\dfrac{1}{1 + e^{-\\theta^{T}x}}$$\n",
    "\n",
    "Also, this term here in the square brackets is the new partial derivative for respect of theta J of the new cost function J of theta. Where J of theta here is the cost function we defined on a previous slide that does use regularization. \n",
    "$$ \\dfrac{\\partial}{\\partial\\theta_{j}}J(\\theta) = \\Big[\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{j}\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic17.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression) 3:44*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic18.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression) 3:54*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Advanced optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about how to get regularized linear regression to work using the more advanced optimization methods. And just to remind you for those methods what we needed to do was to define the function that's called the cost function, that takes us input the parameter vector theta.\n",
    "\n",
    "So we had theta 0 up to theta N. But because Octave indexes the vectors starting from 1. Theta 0 is written in Octave as theta 1. And what we needed to do was provide a function, called cost function.\n",
    "\n",
    "We will use the fminunc (fmin unconstrained), and pass in the @costFunction, and this will work with fminunc was what will take the cost function and minimize it for us.\n",
    "\n",
    "Looking at the function below:\n",
    "\n",
    "```octave\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "jVal = [code to compute J of theta];\n",
    "gradient(1) = [code to compute partial derivative of J of theta];\n",
    "gradient(2) = [code to compute partial derivative of J of theta];\n",
    "```\n",
    "So the two main things that the cost function needed to return: **jVal and gradient**. Now, when we're using regularized logistic regression, of course the cost function j of theta changes and, in particular, now a cost function needs to include this additional regularization term at the end as well. So, when you compute j of theta be sure to include that term at the end.\n",
    "\n",
    "$$J(\\theta) = -\\big[\\dfrac{1}{m}\\sum_{i=1}^m y^{(i)}\\log (h_{\\theta}(x^{(i)}) + (1 - y^{(i)})\\log (1 - h_{\\theta}(x^{(i)})\\big]+ \\lambda\\sum_{i=1}^n\\theta_{j}^2$$\n",
    "\n",
    "And then, the other thing that this cost function thing needs to derive with a gradient. So gradient one needs to be set to the partial derivative of J of theta with respect to theta zero, gradient two needs to be set to that, and so on. Once again, the index is off by one.\n",
    "\n",
    "So, gradient(1) doesn't change. Because the derivative for theta zero doesn't change\n",
    "\n",
    "- gradient(1) = $\\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)}$\n",
    "\n",
    "And the other terms do change:\n",
    "- gradient(2) = $\\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{1}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{1}$\n",
    "- gradient(3) = $\\dfrac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_{2}^{(i)} + \\dfrac{\\lambda}{m}\\theta_{2}$\n",
    "\n",
    "So if you implement this cost function and pass this into fminunc or to one of those advanced optimization techniques, that will minimize the new regularized cost function J of theta. And the parameters you get out will be the ones that correspond to logistic regression with regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec7_pic19.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression) 7:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
